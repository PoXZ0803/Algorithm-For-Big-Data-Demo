{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(output, labels):\n",
        "    # Find manimum element of each \n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    \n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(path=\"./data/cora/\", dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
        "                                        dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
        "                                    dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
        "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
        "                        shape=(labels.shape[0], labels.shape[0]),\n",
        "                        dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    features = normalize(features)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(200, 500)\n",
        "    idx_test = range(500, 1500)\n",
        "\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "class SGC(nn.Module):\n",
        "    def __init__(self, k, nfeat, nclass):\n",
        "        super(SGC, self).__init__()\n",
        "        self.k = k\n",
        "        self.W = nn.Linear(nfeat, nclass)\n",
        "\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        k = self.k\n",
        "        for i in range(k):\n",
        "            x = torch.spmm(adj, x)\n",
        "        x = self.W(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cora dataset...\n"
          ]
        }
      ],
      "source": [
        "adj, features, labels, idx_train, idx_val, idx_test = load_data()\n",
        "\n",
        "# Parameters currently hard coded \n",
        "epochs = 200\n",
        "k = 2\n",
        "lr = 0.2\n",
        "wd = 0.000001\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Model and optmizer\n",
        "\n",
        "model = SGC(k, features.size(1), labels.max().item()+1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
        "                           weight_decay=wd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 1.9456653594970703 Validation Acc 0.49333333333333335\n",
            "Epoch: 10 Loss: 0.8221799731254578 Validation Acc 0.7933333333333333\n",
            "Epoch: 20 Loss: 0.3835243582725525 Validation Acc 0.83\n",
            "Epoch: 30 Loss: 0.2209903746843338 Validation Acc 0.8233333333333334\n",
            "Epoch: 40 Loss: 0.15177805721759796 Validation Acc 0.8233333333333334\n",
            "Epoch: 50 Loss: 0.11864215135574341 Validation Acc 0.8166666666666667\n",
            "Epoch: 60 Loss: 0.10149743407964706 Validation Acc 0.81\n",
            "Epoch: 70 Loss: 0.09164921194314957 Validation Acc 0.8166666666666667\n",
            "Epoch: 80 Loss: 0.08530830591917038 Validation Acc 0.8166666666666667\n",
            "Epoch: 90 Loss: 0.08068900555372238 Validation Acc 0.8133333333333334\n",
            "Epoch: 100 Loss: 0.07700848579406738 Validation Acc 0.81\n",
            "Epoch: 110 Loss: 0.0739065557718277 Validation Acc 0.8066666666666666\n",
            "Epoch: 120 Loss: 0.07122986763715744 Validation Acc 0.8033333333333333\n",
            "Epoch: 130 Loss: 0.0688970685005188 Validation Acc 0.8033333333333333\n",
            "Epoch: 140 Loss: 0.06685230880975723 Validation Acc 0.8066666666666666\n",
            "Epoch: 150 Loss: 0.06505313515663147 Validation Acc 0.8033333333333333\n",
            "Epoch: 160 Loss: 0.06346238404512405 Validation Acc 0.8033333333333333\n",
            "Epoch: 170 Loss: 0.06204914301633835 Validation Acc 0.8033333333333333\n",
            "Epoch: 180 Loss: 0.06078670918941498 Validation Acc 0.8033333333333333\n",
            "Epoch: 190 Loss: 0.059653159230947495 Validation Acc 0.8\n",
            "Test Acc: 0.816\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\tmodel.train()\n",
        "\toptimizer.zero_grad()\n",
        "\toutput = model(features, adj)\n",
        "\tloss_train = torch.nn.functional.cross_entropy(output[idx_train], labels[idx_train])\n",
        "\tloss_train.backward()\n",
        "\toptimizer.step()\n",
        "\tif epoch % 10 == 0:\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tmodel.eval()\n",
        "\t\t\toutput = model(features, adj)\n",
        "\t\t\tacc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "\t\t\tprint(\"Epoch:\", epoch, \"Loss:\", loss_train.item(), \"Validation Acc\",format(acc_val))\n",
        "\n",
        "model.eval()\n",
        "output = model(features, adj)\n",
        "acc_val = accuracy(output[idx_test], labels[idx_test])\n",
        "print(\"Test Acc:\", format(acc_val))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
