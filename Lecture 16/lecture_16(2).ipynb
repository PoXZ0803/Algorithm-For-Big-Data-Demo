{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(path=\"./data/cora/\", dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
        "                                        dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
        "                                    dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
        "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
        "                        shape=(labels.shape[0], labels.shape[0]),\n",
        "                        dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    features = normalize(features)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(200, 500)\n",
        "    idx_test = range(500, 1500)\n",
        "\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(output, labels):\n",
        "    # Find manimum element of each \n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    \n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "class SGC(nn.Module):\n",
        "    def __init__(self, k, nfeat, nclass):\n",
        "        super(SGC, self).__init__()\n",
        "        self.k = k\n",
        "        self.W = nn.Linear(nfeat, nclass)\n",
        "\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        k = self.k\n",
        "        for i in range(k):\n",
        "            x = torch.spmm(adj, x)\n",
        "        x = self.W(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cora dataset...\n",
            "Validation Loss 0.81\n",
            "Test Error: 0.812\n"
          ]
        }
      ],
      "source": [
        "adj, features, labels, idx_train, idx_val, idx_test = load_data()\n",
        "\n",
        "# Parameters currently hard coded \n",
        "epochs = 100\n",
        "k = 2\n",
        "lr = 0.2\n",
        "wd = 0.000001\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Model and optmizer\n",
        "\n",
        "model = SGC(k, features.size(1), labels.max().item()+1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
        "                           weight_decay=wd)\n",
        "\n",
        "# Training\n",
        "\n",
        "for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(features, adj)\n",
        "        loss_train = torch.nn.functional.cross_entropy(output[idx_train], labels[idx_train])\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "with torch.no_grad():\n",
        "            model.eval()\n",
        "            output = model(features, adj)\n",
        "            acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "            print(\"Validation Loss\",format(acc_val))\n",
        "\n",
        "model.eval()\n",
        "output = model(features, adj)\n",
        "acc_val = accuracy(output[idx_test], labels[idx_test])\n",
        "print(\"Test Error:\", format(acc_val))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
