{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import dgl.data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "Number of categories: 7\n"
          ]
        }
      ],
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "print(f\"Number of categories: {dataset.num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A DGL Dataset object may contain one or multiple graphs. The Cora\n",
        "dataset used in this tutorial only consists of one single graph.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g = dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A DGL graph can store node features and edge features in two\n",
        "dictionary-like attributes called ``ndata`` and ``edata``.\n",
        "In the DGL Cora dataset, the graph contains the following node features:\n",
        "\n",
        "- ``train_mask``: A boolean tensor indicating whether the node is in the\n",
        "  training set.\n",
        "\n",
        "- ``val_mask``: A boolean tensor indicating whether the node is in the\n",
        "  validation set.\n",
        "\n",
        "- ``test_mask``: A boolean tensor indicating whether the node is in the\n",
        "  test set.\n",
        "\n",
        "- ``label``: The ground truth node category.\n",
        "\n",
        "-  ``feat``: The node features.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node features\n",
            "{'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False])}\n",
            "Edge features\n",
            "{}\n"
          ]
        }
      ],
      "source": [
        "print(\"Node features\")\n",
        "print(g.ndata)\n",
        "print(\"Edge features\")\n",
        "print(g.edata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "# Create the model with given dimensions\n",
        "model = GCN(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DGL provides implementation of many popular neighbor aggregation\n",
        "modules. You can easily invoke them with one line of code.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training the GCN\n",
        "----------------\n",
        "\n",
        "Training this GCN is similar to training other PyTorch neural networks.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 1.946, val acc: 0.122 (best 0.122), test acc: 0.099 (best 0.099)\n",
            "In epoch 5, loss: 1.903, val acc: 0.572 (best 0.572), test acc: 0.592 (best 0.592)\n",
            "In epoch 10, loss: 1.831, val acc: 0.616 (best 0.616), test acc: 0.630 (best 0.630)\n",
            "In epoch 15, loss: 1.736, val acc: 0.660 (best 0.660), test acc: 0.695 (best 0.695)\n",
            "In epoch 20, loss: 1.620, val acc: 0.694 (best 0.694), test acc: 0.726 (best 0.726)\n",
            "In epoch 25, loss: 1.483, val acc: 0.698 (best 0.704), test acc: 0.740 (best 0.739)\n",
            "In epoch 30, loss: 1.329, val acc: 0.716 (best 0.716), test acc: 0.747 (best 0.747)\n",
            "In epoch 35, loss: 1.166, val acc: 0.734 (best 0.734), test acc: 0.760 (best 0.760)\n",
            "In epoch 40, loss: 1.002, val acc: 0.738 (best 0.740), test acc: 0.758 (best 0.758)\n",
            "In epoch 45, loss: 0.845, val acc: 0.740 (best 0.740), test acc: 0.761 (best 0.758)\n",
            "In epoch 50, loss: 0.701, val acc: 0.748 (best 0.748), test acc: 0.767 (best 0.767)\n",
            "In epoch 55, loss: 0.577, val acc: 0.762 (best 0.762), test acc: 0.773 (best 0.773)\n",
            "In epoch 60, loss: 0.472, val acc: 0.770 (best 0.772), test acc: 0.776 (best 0.776)\n",
            "In epoch 65, loss: 0.387, val acc: 0.772 (best 0.774), test acc: 0.778 (best 0.777)\n",
            "In epoch 70, loss: 0.318, val acc: 0.772 (best 0.774), test acc: 0.779 (best 0.777)\n",
            "In epoch 75, loss: 0.263, val acc: 0.778 (best 0.778), test acc: 0.786 (best 0.783)\n",
            "In epoch 80, loss: 0.219, val acc: 0.780 (best 0.780), test acc: 0.785 (best 0.785)\n",
            "In epoch 85, loss: 0.184, val acc: 0.784 (best 0.784), test acc: 0.786 (best 0.788)\n",
            "In epoch 90, loss: 0.156, val acc: 0.782 (best 0.786), test acc: 0.786 (best 0.787)\n",
            "In epoch 95, loss: 0.134, val acc: 0.784 (best 0.786), test acc: 0.789 (best 0.787)\n"
          ]
        }
      ],
      "source": [
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features = g.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    val_mask = g.ndata[\"val_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "    for e in range(100):\n",
        "        # Forward\n",
        "        logits = model(g, features)\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that you should only compute the losses of the nodes in the training set.\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test accuracy.\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print(\n",
        "                f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
        "            )\n",
        "\n",
        "\n",
        "model = GCN(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train(g, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training on GPU\n",
        "---------------\n",
        "\n",
        "Training on GPU requires to put both the model and the graph onto GPU\n",
        "with the ``to`` method, similar to what you will do in PyTorch.\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "   g = g.to('cuda')\n",
        "   model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes).to('cuda')\n",
        "   train(g, model)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Thumbnail credits: Stanford CS224W Notes\n",
        "# sphinx_gallery_thumbnail_path = '_static/blitz_1_introduction.png'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
